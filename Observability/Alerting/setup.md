This repository documents a production-ready alerting setup built using Grafana Unified Alerting, leveraging both Prometheus (metrics) and Loki (logs) as data sources.

The goal of this setup is to ensure:

High availability of workloads
Early detection of infrastructure issues
Faster incident response
Reduced downtime
Proactive resource management

All alerts are designed following real-world production best practices to maintain cluster stability and application reliability.

üß† Alerting Architecture

Metrics Source: Prometheus
Log Source: Loki
Alert Engine: Grafana Alerting
Notification Channel: Telegram

This allows unified monitoring of:

Infrastructure health
Kubernetes objects
Application behavior
Resource utilization
Crash and failure patterns

üìå Configured Production Alerts
üîπ Deployment Alerts
1Ô∏è‚É£ Deployment-ZeroReplicas
Triggers when a deployment has 0 running replicas, preventing complete application downtime before it impacts users.

2Ô∏è‚É£ Deployment-ReplicaMismatch
Detects mismatch between desired and available replicas, ensuring high availability and proper scaling behavior.

üîπ Node Alerts
3Ô∏è‚É£ Node-NotReady
Alerts when a node becomes NotReady, helping quickly isolate infrastructure or kubelet failures.

4Ô∏è‚É£ Node-HighCPU
Triggers when node CPU usage crosses threshold, preventing performance degradation due to resource exhaustion.

5Ô∏è‚É£ Node-HighMemory
Detects high memory consumption on nodes to avoid OOM events and workload eviction.

üîπ Pod Stability Alerts
6Ô∏è‚É£ Pod-CrashLoopBackOff
Identifies pods repeatedly crashing, enabling faster debugging of faulty deployments or runtime errors.

7Ô∏è‚É£ Pod-ImagePullBackOff
Detects image pull failures early, preventing broken releases from propagating in production.

8Ô∏è‚É£ Pod-OOMKilled
Triggers when containers are killed due to memory limits, helping optimize resource requests and limits.

9Ô∏è‚É£ Pod-StuckPending
Alerts when pods remain in Pending state, identifying scheduling, resource, or taint issues.

üîü Pod-HighRestartRate
Detects abnormal restart patterns to proactively catch unstable applications before user impact.

üîπ Resource Utilization Alerts (Workload Level)
1Ô∏è‚É£1Ô∏è‚É£ Pod-HighCPU
Triggers when pod CPU usage exceeds threshold, helping identify scaling or optimization needs.

1Ô∏è‚É£2Ô∏è‚É£ Pod-HighMemory
Detects excessive memory usage at pod level to prevent application crashes and performance bottlenecks.

Covers infrastructure + workload + failure patterns
Prevents both hard failures and silent degradations
Uses both metrics (Prometheus) and logs (Loki) for deeper visibility
Designed for proactive monitoring instead of reactive firefighting
Supports multi-channel alert notifications
Scalable for large Kubernetes environments

üéØ Outcome

With this alerting framework in place:
MTTR (Mean Time To Recovery) is reduced
Downtime risk is minimized
Scaling issues are detected early
Application instability is caught before escalation
Cluster health remains continuously observable
